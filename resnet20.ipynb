{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resnet20.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMcAoHSMs8ttoQbvQ3eU9cj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0qr6iyLm-aq5"},"outputs":[],"source":["# -*- coding: utf-8 -*-\n","import tensorflow as tf\n","import keras\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.layers import AveragePooling2D, Input, Flatten\n","from keras import optimizers\n","# from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.regularizers import l2\n","from keras.models import Model\n","from keras.utils import np_utils\n","import numpy as np\n","import os\n","\n","\n","# from load_data import load_data\n","from keras.datasets import cifar10\n","\n","# Training parameters\n","batch_size = 32\n","epochs = 100\n","num_classes = 10\n","\n","# Subtracting pixel mean improves accuracy\n","subtract_pixel_mean = True\n","\n","n = 3\n","\n","# Model version\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n","version = 1\n","\n","# Computed depth from supplied model parameter n\n","depth = n * 6 + 2\n","\n","# Model name, depth and version\n","model_type = 'ResNet%dv%d' % (depth, version)\n","\n","# Load the CIFAR10 data.\n","\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('load data successfully!')\n","\n","# Input image dimensions.\n","input_shape = x_train.shape[1:]\n","\n","# Normalize data.\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255\n","\n","# If subtract pixel mean is enabled\n","if subtract_pixel_mean:\n","    x_train_mean = np.mean(x_train, axis=0)\n","    x_train -= x_train_mean\n","    x_test -= x_train_mean\n","\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","print('y_train shape:', y_train.shape)\n","\n","# Convert class vectors to binary class matrices.\n","y_train = np_utils.to_categorical(y_train, num_classes)\n","y_test = np_utils.to_categorical(y_test, num_classes)\n","print('Begin model training...')\n","\n","\n","# Learning Rate Schedule\n","def lr_schedule(epoch):\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr\n","\n","\n","# resnet layer\n","def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x\n","\n","\n","def resnet_v1(input_shape, depth, num_classes=10):\n","    # ResNet Version 1 Model builder [a]\n","    if (depth - 2) % 6 != 0:\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n","    # Start model definition.\n","    num_filters = 16\n","    num_res_blocks = int((depth - 2) / 6)\n","\n","    inputs = Input(shape=input_shape)\n","    x = resnet_layer(inputs=inputs)\n","    # Instantiate the stack of residual units\n","    for stack in range(3):\n","        for res_block in range(num_res_blocks):\n","            strides = 1\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                strides = 2  # downsample\n","            y = resnet_layer(inputs=x,\n","                             num_filters=num_filters,\n","                             strides=strides)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters,\n","                             activation=None)\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","            x = keras.layers.add([x, y])\n","            x = Activation('relu')(x)\n","        num_filters *= 2\n","\n","    # Add classifier on top.\n","    # v1 does not use BN after last shortcut connection-ReLU\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,\n","                    activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","\n","model = resnet_v1(input_shape=input_shape, depth=depth, num_classes=num_classes)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(lr=lr_schedule(0)),\n","              metrics=['accuracy'])\n","model.summary()\n","print(model_type)\n","\n","# Prepare model model saving directory.\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'garbage_%s_model.{epoch:03d}.h5' % model_type\n","if not os.path.isdir(save_dir):\n","    os.makedirs(save_dir)\n","filepath = os.path.join(save_dir, model_name)\n","\n","# Prepare callbacks for model saving and for learning rate adjustment.\n","checkpoint = ModelCheckpoint(filepath=filepath,\n","                             monitor='val_acc',\n","                             verbose=1,\n","                             save_best_only=True)\n","\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                               cooldown=0,\n","                               patience=5,\n","                               min_lr=0.5e-6)\n","\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\n","\n","# Run training, with or without data augmentation.\n","print('Using real-time data augmentation.')\n","# This will do preprocessing and realtime data augmentation:\n","datagen = ImageDataGenerator(\n","        # set input mean to 0 over the dataset\n","        featurewise_center=False,\n","        # set each sample mean to 0\n","        samplewise_center=False,\n","        # divide inputs by std of dataset\n","        featurewise_std_normalization=False,\n","        # divide each input by its std\n","        samplewise_std_normalization=False,\n","        # apply ZCA whitening\n","        zca_whitening=False,\n","        # epsilon for ZCA whitening\n","        zca_epsilon=1e-06,\n","        # randomly rotate images in the range (deg 0 to 180)\n","        rotation_range=0,\n","        # randomly shift images horizontally\n","        width_shift_range=0.1,\n","        # randomly shift images vertically\n","        height_shift_range=0.1,\n","        # set range for random shear\n","        shear_range=0.,\n","        # set range for random zoom\n","        zoom_range=0.,\n","        # set range for random channel shifts\n","        channel_shift_range=0.,\n","        # set mode for filling points outside the input boundaries\n","        fill_mode='nearest',\n","        # value used for fill_mode = \"constant\"\n","        cval=0.,\n","        # randomly flip images\n","        horizontal_flip=True,\n","        # randomly flip images\n","        vertical_flip=False,\n","        # set rescaling factor (applied before any other transformation)\n","        rescale=None,\n","        # set function that will be applied on each input\n","        preprocessing_function=None,\n","        # image data format, either \"channels_first\" or \"channels_last\"\n","        data_format=None,\n","        # fraction of images reserved for validation (strictly between 0 and 1)\n","        validation_split=0.0)\n","\n","# Compute quantities required for featurewise normalization\n","# (std, mean, and principal components if ZCA whitening is applied).\n","datagen.fit(x_train)\n","\n","# Fit the model on the batches generated by datagen.flow().\n","model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                    steps_per_epoch=len(x_train) // batch_size,\n","                    validation_data=(x_test, y_test),\n","                    epochs=epochs, verbose=1, workers=4,\n","                    callbacks=callbacks)\n","\n","# Score trained model.\n","scores = model.evaluate(x_test, y_test, verbose=1)\n","print('Test loss:', scores[0])\n","print('Test accuracy:', scores[1])\n","model.save('./resnet20.h5')"]}]}